{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbccda36",
   "metadata": {},
   "source": [
    "# LLM Zoomcamp - Evaluation Homework\n",
    "\n",
    "This notebook demonstrates various evaluation techniques for search systems and RAG (Retrieval-Augmented Generation) pipelines. We'll explore:\n",
    "\n",
    "1. **Text-based search evaluation** using MinSearch with different boosting parameters\n",
    "2. **Vector search evaluation** using TF-IDF and SVD embeddings\n",
    "3. **Advanced vector search** with Qdrant and modern embedding models\n",
    "4. **Answer similarity evaluation** using cosine similarity and ROUGE metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47218b08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting minsearch\n",
      "  Downloading minsearch-0.0.4-py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: qdrant_client in d:\\program files\\python310\\enviroments\\llmenvs\\lib\\site-packages (1.14.3)\n",
      "Collecting qdrant_client\n",
      "  Downloading qdrant_client-1.15.1-py3-none-any.whl (337 kB)\n",
      "     ------------------------------------- 337.3/337.3 kB 21.8 MB/s eta 0:00:00\n",
      "Collecting pandas\n",
      "  Using cached pandas-2.3.1-cp310-cp310-win_amd64.whl (11.3 MB)\n",
      "Requirement already satisfied: numpy in d:\\program files\\python310\\enviroments\\llmenvs\\lib\\site-packages (from minsearch) (2.2.6)\n",
      "Requirement already satisfied: scikit-learn in d:\\program files\\python310\\enviroments\\llmenvs\\lib\\site-packages (from minsearch) (1.7.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.26.14 in d:\\program files\\python310\\enviroments\\llmenvs\\lib\\site-packages (from qdrant_client) (1.26.20)\n",
      "Requirement already satisfied: httpx[http2]>=0.20.0 in d:\\program files\\python310\\enviroments\\llmenvs\\lib\\site-packages (from qdrant_client) (0.28.1)\n",
      "Requirement already satisfied: pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8 in d:\\program files\\python310\\enviroments\\llmenvs\\lib\\site-packages (from qdrant_client) (2.11.6)\n",
      "Requirement already satisfied: protobuf>=3.20.0 in d:\\program files\\python310\\enviroments\\llmenvs\\lib\\site-packages (from qdrant_client) (6.31.1)\n",
      "Requirement already satisfied: portalocker<4.0,>=2.7.0 in d:\\program files\\python310\\enviroments\\llmenvs\\lib\\site-packages (from qdrant_client) (2.10.1)\n",
      "Requirement already satisfied: grpcio>=1.41.0 in d:\\program files\\python310\\enviroments\\llmenvs\\lib\\site-packages (from qdrant_client) (1.73.1)\n",
      "Requirement already satisfied: certifi in d:\\program files\\python310\\enviroments\\llmenvs\\lib\\site-packages (from httpx[http2]>=0.20.0->qdrant_client) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\program files\\python310\\enviroments\\llmenvs\\lib\\site-packages (from httpx[http2]>=0.20.0->qdrant_client) (1.0.9)\n",
      "Requirement already satisfied: idna in d:\\program files\\python310\\enviroments\\llmenvs\\lib\\site-packages (from httpx[http2]>=0.20.0->qdrant_client) (3.10)\n",
      "Requirement already satisfied: anyio in d:\\program files\\python310\\enviroments\\llmenvs\\lib\\site-packages (from httpx[http2]>=0.20.0->qdrant_client) (4.9.0)\n",
      "Requirement already satisfied: h2<5,>=3 in d:\\program files\\python310\\enviroments\\llmenvs\\lib\\site-packages (from httpx[http2]>=0.20.0->qdrant_client) (4.2.0)\n",
      "Requirement already satisfied: h11>=0.16 in d:\\program files\\python310\\enviroments\\llmenvs\\lib\\site-packages (from httpcore==1.*->httpx[http2]>=0.20.0->qdrant_client) (0.16.0)\n",
      "Requirement already satisfied: pywin32>=226 in d:\\program files\\python310\\enviroments\\llmenvs\\lib\\site-packages (from portalocker<4.0,>=2.7.0->qdrant_client) (310)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in d:\\program files\\python310\\enviroments\\llmenvs\\lib\\site-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8->qdrant_client) (0.7.0)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in d:\\program files\\python310\\enviroments\\llmenvs\\lib\\site-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8->qdrant_client) (4.14.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in d:\\program files\\python310\\enviroments\\llmenvs\\lib\\site-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8->qdrant_client) (0.4.1)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in d:\\program files\\python310\\enviroments\\llmenvs\\lib\\site-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8->qdrant_client) (2.33.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\program files\\python310\\enviroments\\llmenvs\\lib\\site-packages (from pandas->minsearch) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\program files\\python310\\enviroments\\llmenvs\\lib\\site-packages (from pandas->minsearch) (2025.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\program files\\python310\\enviroments\\llmenvs\\lib\\site-packages (from pandas->minsearch) (2025.2)\n",
      "Requirement already satisfied: scipy>=1.8.0 in d:\\program files\\python310\\enviroments\\llmenvs\\lib\\site-packages (from scikit-learn->minsearch) (1.15.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in d:\\program files\\python310\\enviroments\\llmenvs\\lib\\site-packages (from scikit-learn->minsearch) (3.6.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in d:\\program files\\python310\\enviroments\\llmenvs\\lib\\site-packages (from scikit-learn->minsearch) (1.5.1)\n",
      "Requirement already satisfied: hyperframe<7,>=6.1 in d:\\program files\\python310\\enviroments\\llmenvs\\lib\\site-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant_client) (6.1.0)\n",
      "Requirement already satisfied: hpack<5,>=4.1 in d:\\program files\\python310\\enviroments\\llmenvs\\lib\\site-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant_client) (4.1.0)\n",
      "Requirement already satisfied: six>=1.5 in d:\\program files\\python310\\enviroments\\llmenvs\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->minsearch) (1.17.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in d:\\program files\\python310\\enviroments\\llmenvs\\lib\\site-packages (from anyio->httpx[http2]>=0.20.0->qdrant_client) (1.3.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in d:\\program files\\python310\\enviroments\\llmenvs\\lib\\site-packages (from anyio->httpx[http2]>=0.20.0->qdrant_client) (1.3.0)\n",
      "Installing collected packages: pandas, minsearch, qdrant_client\n",
      "  Attempting uninstall: qdrant_client\n",
      "    Found existing installation: qdrant-client 1.14.3\n",
      "    Uninstalling qdrant-client-1.14.3:\n",
      "      Successfully uninstalled qdrant-client-1.14.3\n",
      "Successfully installed minsearch-0.0.4 pandas-2.3.1 qdrant_client-1.15.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Install required packages for the evaluation homework\n",
    "# - minsearch: A lightweight search engine for text and vector search\n",
    "# - qdrant_client: Python client for Qdrant vector database\n",
    "# The -q flag suppresses verbose output during installation\n",
    "!pip install -U minsearch qdrant_client -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ceb3c1",
   "metadata": {},
   "source": [
    "## Evaluation data\n",
    "\n",
    "For this homework, we will use the same dataset we generated\n",
    "in the videos.\n",
    "\n",
    "Let's get them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3b3455",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import essential libraries for data handling and HTTP requests\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# Define the base URL for accessing evaluation datasets from the LLM Zoomcamp repository\n",
    "url_prefix = 'https://raw.githubusercontent.com/DataTalksClub/llm-zoomcamp/main/03-evaluation/'\n",
    "\n",
    "# Load the documents dataset\n",
    "# This contains FAQ documents with unique IDs that we'll use for retrieval evaluation\n",
    "docs_url = url_prefix + 'search_evaluation/documents-with-ids.json'\n",
    "documents = requests.get(docs_url).json()\n",
    "\n",
    "# Load the ground truth dataset\n",
    "# This contains question-answer pairs with known correct document associations\n",
    "# Each record has a question, the course it belongs to, and the document ID that should be retrieved\n",
    "ground_truth_url = url_prefix + 'search_evaluation/ground-truth-data.csv'\n",
    "df_ground_truth = pd.read_csv(ground_truth_url)\n",
    "\n",
    "# Convert DataFrame to list of dictionaries for easier processing\n",
    "ground_truth = df_ground_truth.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16eb4e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': \"The purpose of this document is to capture frequently asked technical questions\\nThe exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\\nSubscribe to course public Google Calendar (it works from Desktop only).\\nRegister before the course starts using this link.\\nJoin the course Telegram channel with announcements.\\nDon’t forget to register in DataTalks.Club's Slack and join the channel.\",\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Course - When will the course start?',\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  'id': 'c02e79ef'},\n",
       " {'text': 'GitHub - DataTalksClub data-engineering-zoomcamp#prerequisites',\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Course - What are the prerequisites for this course?',\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  'id': '1f6520ca'},\n",
       " {'text': \"Yes, even if you don't register, you're still eligible to submit the homeworks.\\nBe aware, however, that there will be deadlines for turning in the final projects. So don't leave everything for the last minute.\",\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Course - Can I still join the course after the start date?',\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  'id': '7842b56a'}]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examine the structure of the first 3 documents\n",
    "# Each document contains: id, question, text (answer), section, and course\n",
    "documents[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713f0a07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'question': 'When does the course begin?',\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  'document': 'c02e79ef'},\n",
       " {'question': 'How can I get the course schedule?',\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  'document': 'c02e79ef'},\n",
       " {'question': 'What is the link for course registration?',\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  'document': 'c02e79ef'}]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examine the structure of the first 3 ground truth records\n",
    "# Each record contains: question, course, and document (the correct document ID for this question)\n",
    "ground_truth[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1e3742",
   "metadata": {},
   "source": [
    "Here, `documents` contains the documents from the FAQ database\n",
    "with unique IDs, and `ground_truth` contains generated\n",
    "question-answer pairs. \n",
    "\n",
    "Also, we will need the code for evaluating retrieval:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9928d39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import tqdm for progress bars during evaluation\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "def hit_rate(relevance_total):\n",
    "    \"\"\"\n",
    "    Calculate Hit Rate: the proportion of queries for which at least one relevant document \n",
    "    was retrieved in the top-k results.\n",
    "    \n",
    "    Args:\n",
    "        relevance_total: List of lists, where each inner list contains boolean values\n",
    "                        indicating whether each retrieved document is relevant\n",
    "    \n",
    "    Returns:\n",
    "        float: Hit rate between 0 and 1\n",
    "    \"\"\"\n",
    "    cnt = 0\n",
    "    \n",
    "    # Count queries where at least one relevant document was found\n",
    "    for line in relevance_total:\n",
    "        if True in line:  # At least one relevant document found\n",
    "            cnt += 1\n",
    "    \n",
    "    return cnt / len(relevance_total)\n",
    "\n",
    "def mrr(relevance_total):\n",
    "    \"\"\"\n",
    "    Calculate Mean Reciprocal Rank (MRR): measures the average of reciprocal ranks\n",
    "    of the first relevant document for each query.\n",
    "    \n",
    "    Args:\n",
    "        relevance_total: List of lists, where each inner list contains boolean values\n",
    "                        indicating whether each retrieved document is relevant\n",
    "    \n",
    "    Returns:\n",
    "        float: MRR score between 0 and 1\n",
    "    \"\"\"\n",
    "    total_score = 0.0\n",
    "    \n",
    "    # For each query, find the rank of the first relevant document\n",
    "    for line in relevance_total:\n",
    "        for rank in range(len(line)):\n",
    "            if line[rank] == True:  # Found first relevant document\n",
    "                # Add reciprocal of rank (1-indexed) to total score\n",
    "                total_score += 1 / (rank + 1)\n",
    "                break  # Only consider the first relevant document\n",
    "    \n",
    "    return total_score / len(relevance_total)\n",
    "\n",
    "def evaluate(ground_truth, search_function):\n",
    "    \"\"\"\n",
    "    Evaluate a search function using hit rate and MRR metrics.\n",
    "    \n",
    "    Args:\n",
    "        ground_truth: List of dictionaries containing question, course, and document\n",
    "        search_function: Function that takes a ground truth record and returns search results\n",
    "    \n",
    "    Returns:\n",
    "        dict: Dictionary containing 'hit_rate' and 'mrr' scores\n",
    "    \"\"\"\n",
    "    relevance_total = []\n",
    "    \n",
    "    # Evaluate each question in the ground truth\n",
    "    for q in tqdm(ground_truth):\n",
    "        doc_id = q['document']  # The correct document ID for this question\n",
    "        results = search_function(q)  # Get search results\n",
    "        \n",
    "        # Check which results are relevant (match the correct document ID)\n",
    "        relevance = [d['id'] == doc_id for d in results]\n",
    "        relevance_total.append(relevance)\n",
    "    \n",
    "    # Calculate and return both metrics\n",
    "    return {\n",
    "        'hit_rate': hit_rate(relevance_total),\n",
    "        'mrr': mrr(relevance_total),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89be8fc1",
   "metadata": {},
   "source": [
    "## Q1. Minsearch text\n",
    "\n",
    "Now let's evaluate our usual minsearch approach, indexing documents with:\n",
    "```python\n",
    "text_fields=[\"question\", \"section\", \"text\"],\n",
    "keyword_fields=[\"course\", \"id\"]\n",
    "```\n",
    "but tweak the parameters for search. Let's use the following boosting params:\n",
    "\n",
    "```python\n",
    "boost = {'question': 1.5, 'section': 0.1}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e926cb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<minsearch.minsearch.Index at 0x2bcea7a4130>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the MinSearch library for text-based search\n",
    "import minsearch\n",
    "\n",
    "# Create a MinSearch index with specified field configurations\n",
    "# text_fields: Fields that will be tokenized and used for full-text search\n",
    "# keyword_fields: Fields that will be used for exact matching (filtering)\n",
    "index = minsearch.Index(\n",
    "    text_fields=[\"question\", \"section\", \"text\"],  # Searchable text fields\n",
    "    keyword_fields=[\"course\", \"id\"]  # Fields for exact filtering\n",
    ")\n",
    "\n",
    "# Fit the index with our documents dataset\n",
    "# This builds the internal search structures (inverted index, etc.)\n",
    "index.fit(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab2a9d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "254a89a6fc7a4993ab8053968a8e06cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4627 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import tqdm again (if not already imported in current kernel session)\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "def minsearch_search(query, course):\n",
    "    \"\"\"\n",
    "    Perform text-based search using MinSearch with custom boosting parameters.\n",
    "    \n",
    "    Args:\n",
    "        query (str): The search query\n",
    "        course (str): The course to filter by\n",
    "    \n",
    "    Returns:\n",
    "        list: List of search results (documents)\n",
    "    \"\"\"\n",
    "    # Define boosting parameters to weight different fields\n",
    "    # Higher values = more importance in ranking\n",
    "    boost = {\n",
    "        'question': 1.5,  # Give more weight to matches in the question field\n",
    "        'section': 0.1    # Give less weight to matches in the section field\n",
    "    }\n",
    "    \n",
    "    # Perform the search with boosting and filtering\n",
    "    results = index.search(\n",
    "        query=query,\n",
    "        filter_dict={'course': course},  # Only return documents from the specified course\n",
    "        boost_dict=boost,  # Apply field boosting\n",
    "        num_results=5  # Return top 5 results\n",
    "    )\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d668fba3",
   "metadata": {},
   "source": [
    "What's the hitrate for this approach?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7badc03c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d449bb29e887477ead45a70f7ab7d5f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4627 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'hit_rate': 0.848714069591528, 'mrr': 0.7288235717887772}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the MinSearch approach with boosting parameters\n",
    "# Using lambda function to create a search function that matches our evaluation interface\n",
    "# This will calculate both hit rate and MRR for the text-based search approach\n",
    "minsearch_results = evaluate(ground_truth, lambda q: minsearch_search(q['question'], q['course']))\n",
    "print(\"MinSearch Evaluation Results:\")\n",
    "print(f\"Hit Rate: {minsearch_results['hit_rate']:.3f}\")\n",
    "print(f\"MRR: {minsearch_results['mrr']:.3f}\")\n",
    "\n",
    "minsearch_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8afc5bcc",
   "metadata": {},
   "source": [
    "## Embeddings \n",
    "\n",
    "The latest version of minsearch also supports vector search. \n",
    "We will use it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a662c700",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import VectorSearch from minsearch for vector-based similarity search\n",
    "from minsearch import VectorSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c9e892",
   "metadata": {},
   "source": [
    "We will also use TF-IDF and Singular Value Decomposition to \n",
    "create embeddings from texts. You can refer to our\n",
    "[\"Create Your Own Search Engine\" workshop](https://github.com/alexeygrigorev/build-your-own-search-engine)\n",
    "if you want to know more about it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3bac7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import scikit-learn components for creating embeddings\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer  # Convert text to TF-IDF vectors\n",
    "from sklearn.decomposition import TruncatedSVD  # Dimensionality reduction using SVD\n",
    "from sklearn.pipeline import make_pipeline  # Create ML pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074a096f",
   "metadata": {},
   "source": [
    "Let's create embeddings for the \"question\" field:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8095c73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract text content from documents for embedding creation\n",
    "# We'll use only the 'question' field for this first vector search experiment\n",
    "texts = []\n",
    "\n",
    "for doc in documents:\n",
    "    text_content = doc['question']  # Extract the question text\n",
    "    texts.append(text_content)\n",
    "\n",
    "print(f\"Extracted {len(texts)} question texts for embedding creation\")\n",
    "\n",
    "# Create a machine learning pipeline for text embeddings\n",
    "# Pipeline steps:\n",
    "# 1. TfidfVectorizer: Convert text to TF-IDF vectors (min_df=3 filters rare words)\n",
    "# 2. TruncatedSVD: Reduce dimensionality to 128 components for efficiency\n",
    "pipeline = make_pipeline(\n",
    "    TfidfVectorizer(min_df=3),  # Ignore terms that appear in fewer than 3 documents\n",
    "    TruncatedSVD(n_components=128, random_state=1)  # Reduce to 128 dimensions\n",
    ")\n",
    "\n",
    "# Fit the pipeline and transform texts to embeddings\n",
    "print(\"Creating embeddings using TF-IDF + SVD pipeline...\")\n",
    "X = pipeline.fit_transform(texts)\n",
    "print(f\"Created embeddings with shape: {X.shape}\")  # Should be (num_documents, 128)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526f316f",
   "metadata": {},
   "source": [
    "## Q2. Vector search for question\n",
    "\n",
    "Now let's index these embeddings with minsearch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d814ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<minsearch.vector.VectorSearch at 0x2bc8b5ed360>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a vector search index using the embeddings\n",
    "# keyword_fields specifies which fields can be used for filtering\n",
    "vindex = VectorSearch(keyword_fields={'course'})\n",
    "\n",
    "# Fit the vector index with our embeddings and document metadata\n",
    "# X: The embedding vectors we created\n",
    "# documents: The original documents with metadata for filtering\n",
    "print(\"Creating vector search index...\")\n",
    "vindex.fit(X, documents)\n",
    "print(\"Vector index created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d341921",
   "metadata": {},
   "source": [
    "Evaluate this search method. What's MRR for it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d04bcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ead38843c4a4afa87e67bfbe3a51c5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4627 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'hit_rate': 0.48173762697212014, 'mrr': 0.3572833369353793}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def vector_search(query, course):\n",
    "    \"\"\"\n",
    "    Perform vector-based search using embeddings created with TF-IDF + SVD.\n",
    "    \n",
    "    Args:\n",
    "        query (str): The search query\n",
    "        course (str): The course to filter by\n",
    "    \n",
    "    Returns:\n",
    "        list: List of search results (documents) ranked by vector similarity\n",
    "    \"\"\"\n",
    "    # Transform the query using the same pipeline used for documents\n",
    "    # This ensures the query is in the same vector space as the indexed documents\n",
    "    X_query = pipeline.transform([query])\n",
    "    \n",
    "    # Perform vector similarity search\n",
    "    results = vindex.search(\n",
    "        query_vector=X_query,  # The query vector\n",
    "        filter_dict={'course': course},  # Filter by course\n",
    "        num_results=5  # Return top 5 most similar documents\n",
    "    )\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Evaluate the vector search approach using questions from ground truth\n",
    "print(\"Evaluating vector search approach...\")\n",
    "vector_results = evaluate(ground_truth, lambda q: vector_search(q['question'], q['course']))\n",
    "print(\"\\nVector Search Evaluation Results:\")\n",
    "print(f\"Hit Rate: {vector_results['hit_rate']:.3f}\")\n",
    "print(f\"MRR: {vector_results['mrr']:.3f}\")\n",
    "\n",
    "vector_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1867c4b",
   "metadata": {},
   "source": [
    "## Q3. Vector search for question and answer\n",
    "\n",
    "We only used question in Q2. We can use both question and answer:\n",
    "\n",
    "```python\n",
    "texts = []\n",
    "\n",
    "for doc in documents:\n",
    "    t = doc['question'] + ' ' + doc['text']\n",
    "    texts.append(t)\n",
    "```\n",
    "\n",
    "Using the same pipeline (`min_df=3 for TF-IDF vectorizer and `n_components=128` for SVD), evaluate the performance of this\n",
    "approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518c9f25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<minsearch.vector.VectorSearch at 0x2bc8b9466e0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new text corpus combining question and answer text\n",
    "# This approach should provide richer context for vector search\n",
    "texts_combined = []\n",
    "\n",
    "for doc in documents:\n",
    "    # Combine question and answer text with a space separator\n",
    "    combined_text = doc['question'] + ' ' + doc['text']\n",
    "    texts_combined.append(combined_text)\n",
    "\n",
    "print(f\"Created {len(texts_combined)} combined question+answer texts\")\n",
    "\n",
    "# Create a new pipeline with the same parameters for consistency\n",
    "pipeline_combined = make_pipeline(\n",
    "    TfidfVectorizer(min_df=3),  # Same filtering as before\n",
    "    TruncatedSVD(n_components=128, random_state=1)  # Same dimensionality\n",
    ")\n",
    "\n",
    "# Fit the pipeline on the combined texts and create embeddings\n",
    "print(\"Creating embeddings for combined question+answer texts...\")\n",
    "X_combined = pipeline_combined.fit_transform(texts_combined)\n",
    "print(f\"Created combined embeddings with shape: {X_combined.shape}\")\n",
    "\n",
    "# Create a new vector index with the combined embeddings\n",
    "vindex_combined = VectorSearch(keyword_fields={'course'})\n",
    "vindex_combined.fit(X_combined, documents)\n",
    "print(\"Combined vector index created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4616e4",
   "metadata": {},
   "source": [
    "What's the hitrate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b38f55e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba9c286df06045a49c1edaec8dfe595c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4627 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'hit_rate': 0.8210503566025502, 'mrr': 0.6717347453353508}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def vector_search_combined(query, course):\n",
    "    \"\"\"\n",
    "    Perform vector search using embeddings created from combined question+answer text.\n",
    "    \n",
    "    Args:\n",
    "        query (str): The search query\n",
    "        course (str): The course to filter by\n",
    "    \n",
    "    Returns:\n",
    "        list: List of search results ranked by vector similarity\n",
    "    \"\"\"\n",
    "    # Transform query using the combined text pipeline\n",
    "    X_query = pipeline_combined.transform([query])\n",
    "    \n",
    "    # Search using the combined embeddings index\n",
    "    results = vindex_combined.search(\n",
    "        query_vector=X_query,\n",
    "        filter_dict={'course': course},\n",
    "        num_results=5\n",
    "    )\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Evaluate the combined vector search approach\n",
    "print(\"Evaluating combined question+answer vector search...\")\n",
    "combined_results = evaluate(ground_truth, lambda q: vector_search_combined(q['question'], q['course']))\n",
    "print(\"\\nCombined Vector Search Evaluation Results:\")\n",
    "print(f\"Hit Rate: {combined_results['hit_rate']:.3f}\")\n",
    "print(f\"MRR: {combined_results['mrr']:.3f}\")\n",
    "\n",
    "combined_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2693067",
   "metadata": {},
   "source": [
    "## Q4. Qdrant\n",
    "\n",
    "Now let's evaluate the following settings in Qdrant:\n",
    "\n",
    "- `text = doc['question'] + ' ' + doc['text']`\n",
    "- `model_handle = \"jinaai/jina-embeddings-v2-small-en\"`\n",
    "- `limit = 5`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0b45ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import FastEmbed for modern embedding models\n",
    "from fastembed import TextEmbedding\n",
    "\n",
    "# Test query to understand embedding dimensions\n",
    "query = 'I just discovered the course. Can I join now?'\n",
    "\n",
    "# Initialize the Jina embedding model\n",
    "# This is a state-of-the-art embedding model optimized for semantic similarity\n",
    "model_name = 'jinaai/jina-embeddings-v2-small-en'\n",
    "print(f\"Loading embedding model: {model_name}\")\n",
    "\n",
    "model = TextEmbedding(model_name=model_name)\n",
    "\n",
    "# Create embeddings for the test query to determine dimensionality\n",
    "embeddings_query = list(model.embed([query]))\n",
    "embedding_dim = len(embeddings_query[0])\n",
    "print(f\"Embedding dimensionality: {embedding_dim}\")\n",
    "\n",
    "embedding_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8cd61d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UpdateResult(operation_id=0, status=<UpdateStatus.COMPLETED: 'completed'>)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import Qdrant client and models for vector database operations\n",
    "from qdrant_client import QdrantClient, models\n",
    "\n",
    "# Initialize Qdrant client\n",
    "# Assumes Qdrant is running locally on port 6333\n",
    "client = QdrantClient(\"http://localhost:6333\")\n",
    "\n",
    "# Configuration for the vector collection\n",
    "EMBEDDING_DIMENSIONALITY = 512  # Jina embeddings have 512 dimensions\n",
    "collection_name = \"ml-docs\"\n",
    "\n",
    "print(f\"Creating Qdrant collection '{collection_name}' with {EMBEDDING_DIMENSIONALITY} dimensions...\")\n",
    "\n",
    "# Create a new collection in Qdrant\n",
    "# Delete existing collection if it exists to ensure clean state\n",
    "try:\n",
    "    client.delete_collection(collection_name)\n",
    "    print(f\"Deleted existing collection '{collection_name}'\")\n",
    "except:\n",
    "    print(f\"No existing collection '{collection_name}' found\")\n",
    "\n",
    "client.create_collection(\n",
    "    collection_name=collection_name,\n",
    "    vectors_config=models.VectorParams(\n",
    "        size=EMBEDDING_DIMENSIONALITY,  # Vector dimension\n",
    "        distance=models.Distance.COSINE  # Use cosine similarity for distance metric\n",
    "    )\n",
    ")\n",
    "print(\"Collection created successfully!\")\n",
    "\n",
    "# Prepare data points for insertion into Qdrant\n",
    "print(\"Creating embeddings and preparing data points...\")\n",
    "points = []\n",
    "id_ = 0\n",
    "\n",
    "for doc in documents:\n",
    "    # Combine question and answer text (same as our best performing approach)\n",
    "    text = doc['question'] + ' ' + doc['text']\n",
    "    \n",
    "    # Create embedding for this document\n",
    "    embedding_vector = list(model.embed([text]))[0]\n",
    "    \n",
    "    # Create a Qdrant point with embedding and metadata\n",
    "    point = models.PointStruct(\n",
    "        id=id_,  # Unique identifier for this point\n",
    "        vector=embedding_vector,  # The embedding vector\n",
    "        payload={  # Metadata associated with this vector\n",
    "            \"id\": doc[\"id\"],  # Original document ID\n",
    "            \"text\": text,  # The combined text\n",
    "            \"section\": doc['section'],  # Document section\n",
    "            \"course\": doc['course']  # Course name for filtering\n",
    "        }\n",
    "    )\n",
    "    points.append(point)\n",
    "    id_ += 1\n",
    "    \n",
    "    # Print progress every 100 documents\n",
    "    if id_ % 100 == 0:\n",
    "        print(f\"Processed {id_} documents...\")\n",
    "\n",
    "print(f\"Created {len(points)} data points\")\n",
    "\n",
    "# Insert all points into the Qdrant collection\n",
    "print(\"Inserting points into Qdrant...\")\n",
    "client.upsert(\n",
    "    collection_name=collection_name,\n",
    "    points=points\n",
    ")\n",
    "print(\"Data insertion completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7310c948",
   "metadata": {},
   "source": [
    "What's the MRR?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1340966e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a8bef17216a4c5582ed55227f5bcfe8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4627 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'hit_rate': 0.9299762264966501, 'mrr': 0.8517722066133576}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def evaluate_qdrant(ground_truth, search_function):\n",
    "    \"\"\"\n",
    "    Evaluate a Qdrant search function using hit rate and MRR metrics.\n",
    "    This version is adapted for Qdrant's response format.\n",
    "    \n",
    "    Args:\n",
    "        ground_truth: List of dictionaries containing question, course, and document\n",
    "        search_function: Function that takes a ground truth record and returns Qdrant results\n",
    "    \n",
    "    Returns:\n",
    "        dict: Dictionary containing 'hit_rate' and 'mrr' scores\n",
    "    \"\"\"\n",
    "    relevance_total = []\n",
    "    \n",
    "    for q in tqdm(ground_truth):\n",
    "        doc_id = q['document']  # The correct document ID\n",
    "        results = search_function(q)  # Get Qdrant search results\n",
    "        \n",
    "        # Extract document IDs from Qdrant response format\n",
    "        # Qdrant returns results in results.points where each point has a payload\n",
    "        relevance = [d.payload[\"id\"] == doc_id for d in results.points]\n",
    "        relevance_total.append(relevance)\n",
    "    \n",
    "    return {\n",
    "        'hit_rate': hit_rate(relevance_total),\n",
    "        'mrr': mrr(relevance_total),\n",
    "    }\n",
    "\n",
    "def qdrant_search(query, course):\n",
    "    \"\"\"\n",
    "    Perform vector search using Qdrant with Jina embeddings.\n",
    "    \n",
    "    Args:\n",
    "        query (str): The search query\n",
    "        course (str): The course to filter by\n",
    "    \n",
    "    Returns:\n",
    "        QdrantSearchResult: Qdrant search results object\n",
    "    \"\"\"\n",
    "    # Create embedding for the query using the same model as documents\n",
    "    query_embedding = list(model.embed([query]))[0]\n",
    "    \n",
    "    # Perform vector search in Qdrant with course filtering\n",
    "    results = client.query_points(\n",
    "        collection_name=collection_name,\n",
    "        query=query_embedding,  # The query vector\n",
    "        limit=5,  # Return top 5 results\n",
    "        with_payload=True,  # Include metadata in results\n",
    "        query_filter=models.Filter(  # Filter by course\n",
    "            must=[\n",
    "                models.FieldCondition(\n",
    "                    key=\"course\",\n",
    "                    match=models.MatchValue(value=course)\n",
    "                )\n",
    "            ]\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Evaluate Qdrant approach\n",
    "print(\"Evaluating Qdrant vector search with Jina embeddings...\")\n",
    "qdrant_results = evaluate_qdrant(ground_truth, lambda q: qdrant_search(q['question'], q['course']))\n",
    "print(\"\\nQdrant Evaluation Results:\")\n",
    "print(f\"Hit Rate: {qdrant_results['hit_rate']:.3f}\")\n",
    "print(f\"MRR: {qdrant_results['mrr']:.3f}\")\n",
    "\n",
    "qdrant_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c3c5e5",
   "metadata": {},
   "source": [
    "## Q5. Cosine simiarity\n",
    "\n",
    "In the second part of the module, we looked at evaluating\n",
    "the entire RAG approach. In particular, we looked at \n",
    "comparing the answer generated by our system with the actual\n",
    "answer from the FAQ.\n",
    "\n",
    "One of the ways of doing it is using the cosine similarity. \n",
    "Let's see how to calculate it.\n",
    "\n",
    "Cosine similarity is a dot product between two normalized vectors.\n",
    "In geometrical sense, it's the cosine of the angle between\n",
    "the vectors. Look up \"cosine similarity geometry\" if you want to\n",
    "learn more about it.\n",
    "\n",
    "For us, it means that we need two things:\n",
    "\n",
    "- First, we normalize each of the vectors\n",
    "- Then, compute the dot product\n",
    "\n",
    "So, we get this:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528a9b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine(u, v):\n",
    "    \"\"\"\n",
    "    Calculate cosine similarity between two vectors.\n",
    "    \n",
    "    Cosine similarity measures the cosine of the angle between two vectors,\n",
    "    providing a metric of orientation rather than magnitude. It ranges from -1 to 1,\n",
    "    where 1 indicates identical orientation, 0 indicates orthogonality, and -1 indicates opposite orientation.\n",
    "    \n",
    "    Mathematical formula: cos(θ) = (u · v) / (||u|| × ||v||)\n",
    "    \n",
    "    Args:\n",
    "        u, v: Input vectors (numpy arrays or similar)\n",
    "    \n",
    "    Returns:\n",
    "        float: Cosine similarity score\n",
    "    \"\"\"\n",
    "    # Normalize both vectors to unit length\n",
    "    u_normalized = normalize(u)\n",
    "    v_normalized = normalize(v)\n",
    "    \n",
    "    # Compute dot product of normalized vectors\n",
    "    return u_normalized.dot(v_normalized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ccea8b",
   "metadata": {},
   "source": [
    "For normalization, we first compute the vector norm (its length),\n",
    "and then divide the vector by it:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb203820",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import NumPy for mathematical operations\n",
    "import numpy as np\n",
    "\n",
    "def normalize(u):\n",
    "    \"\"\"\n",
    "    Normalize a vector to unit length (L2 normalization).\n",
    "    \n",
    "    This converts the vector to have a magnitude (length) of 1 while preserving its direction.\n",
    "    The L2 norm (Euclidean norm) is calculated as: ||u|| = √(u₁² + u₂² + ... + uₙ²)\n",
    "    \n",
    "    Args:\n",
    "        u: Input vector (numpy array)\n",
    "    \n",
    "    Returns:\n",
    "        numpy array: Normalized vector with unit length\n",
    "    \"\"\"\n",
    "    # Calculate the L2 norm (Euclidean norm) of the vector\n",
    "    norm = np.sqrt(u.dot(u))  # This is equivalent to np.linalg.norm(u)\n",
    "    \n",
    "    # Divide vector by its norm to get unit vector\n",
    "    # Add small epsilon to avoid division by zero\n",
    "    return u / (norm + 1e-10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85273082",
   "metadata": {},
   "source": [
    "Or we can simplify it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73c7c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_simplified(u, v):\n",
    "    \"\"\"\n",
    "    Calculate cosine similarity using a simplified, more efficient approach.\n",
    "    \n",
    "    This version combines normalization and dot product calculation into a single function,\n",
    "    avoiding the intermediate step of creating normalized vectors.\n",
    "    \n",
    "    Mathematical formula: cos(θ) = (u · v) / (||u|| × ||v||)\n",
    "    \n",
    "    Args:\n",
    "        u, v: Input vectors (numpy arrays)\n",
    "    \n",
    "    Returns:\n",
    "        float: Cosine similarity score between -1 and 1\n",
    "    \"\"\"\n",
    "    # Calculate L2 norms of both vectors\n",
    "    u_norm = np.sqrt(u.dot(u))  # ||u||\n",
    "    v_norm = np.sqrt(v.dot(v))  # ||v||\n",
    "    \n",
    "    # Calculate cosine similarity directly\n",
    "    # Add small epsilon to denominator to avoid division by zero\n",
    "    return u.dot(v) / (u_norm * v_norm + 1e-10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8893b916",
   "metadata": {},
   "source": [
    "Now let's use this function to compute the\n",
    "A->Q->A cosine similarity.\n",
    "\n",
    "We will use the results from [our gpt-4o-mini evaluations](https://github.com/DataTalksClub/llm-zoomcamp/blob/main/03-evaluation/rag_evaluation/data/results-gpt4o-mini.csv):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796e3c3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answer_llm</th>\n",
       "      <th>answer_orig</th>\n",
       "      <th>document</th>\n",
       "      <th>question</th>\n",
       "      <th>course</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>You can sign up for the course by visiting the...</td>\n",
       "      <td>Machine Learning Zoomcamp FAQ\\nThe purpose of ...</td>\n",
       "      <td>0227b872</td>\n",
       "      <td>Where can I sign up for the course?</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You can sign up using the link provided in the...</td>\n",
       "      <td>Machine Learning Zoomcamp FAQ\\nThe purpose of ...</td>\n",
       "      <td>0227b872</td>\n",
       "      <td>Can you provide a link to sign up?</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yes, there is an FAQ for the Machine Learning ...</td>\n",
       "      <td>Machine Learning Zoomcamp FAQ\\nThe purpose of ...</td>\n",
       "      <td>0227b872</td>\n",
       "      <td>Is there an FAQ for this Machine Learning course?</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The context does not provide any specific info...</td>\n",
       "      <td>Machine Learning Zoomcamp FAQ\\nThe purpose of ...</td>\n",
       "      <td>0227b872</td>\n",
       "      <td>Does this course have a GitHub repository for ...</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>To structure your questions and answers for th...</td>\n",
       "      <td>Machine Learning Zoomcamp FAQ\\nThe purpose of ...</td>\n",
       "      <td>0227b872</td>\n",
       "      <td>How can I structure my questions and answers f...</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          answer_llm  \\\n",
       "0  You can sign up for the course by visiting the...   \n",
       "1  You can sign up using the link provided in the...   \n",
       "2  Yes, there is an FAQ for the Machine Learning ...   \n",
       "3  The context does not provide any specific info...   \n",
       "4  To structure your questions and answers for th...   \n",
       "\n",
       "                                         answer_orig  document  \\\n",
       "0  Machine Learning Zoomcamp FAQ\\nThe purpose of ...  0227b872   \n",
       "1  Machine Learning Zoomcamp FAQ\\nThe purpose of ...  0227b872   \n",
       "2  Machine Learning Zoomcamp FAQ\\nThe purpose of ...  0227b872   \n",
       "3  Machine Learning Zoomcamp FAQ\\nThe purpose of ...  0227b872   \n",
       "4  Machine Learning Zoomcamp FAQ\\nThe purpose of ...  0227b872   \n",
       "\n",
       "                                            question  \\\n",
       "0                Where can I sign up for the course?   \n",
       "1                 Can you provide a link to sign up?   \n",
       "2  Is there an FAQ for this Machine Learning course?   \n",
       "3  Does this course have a GitHub repository for ...   \n",
       "4  How can I structure my questions and answers f...   \n",
       "\n",
       "                      course  \n",
       "0  machine-learning-zoomcamp  \n",
       "1  machine-learning-zoomcamp  \n",
       "2  machine-learning-zoomcamp  \n",
       "3  machine-learning-zoomcamp  \n",
       "4  machine-learning-zoomcamp  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load pre-computed RAG evaluation results\n",
    "# This dataset contains LLM-generated answers compared to original answers\n",
    "results_url = url_prefix + 'rag_evaluation/data/results-gpt4o-mini.csv'\n",
    "df_results = pd.read_csv(results_url)\n",
    "\n",
    "print(f\"Loaded {len(df_results)} answer pairs for evaluation\")\n",
    "print(\"\\nDataset columns:\", df_results.columns.tolist())\n",
    "print(f\"Sample data shape: {df_results.shape}\")\n",
    "\n",
    "# Display first few rows to understand the data structure\n",
    "df_results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4de957c",
   "metadata": {},
   "source": [
    "When creating embeddings, we will use a simple way -\n",
    "the same we used in the [Embeddings](#embeddings) section:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec367a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new pipeline for answer similarity evaluation\n",
    "# We'll use the same TF-IDF + SVD approach as before for consistency\n",
    "pipeline_similarity = make_pipeline(\n",
    "    TfidfVectorizer(min_df=3),  # Filter rare terms\n",
    "    TruncatedSVD(n_components=128, random_state=1)  # Reduce dimensionality\n",
    ")\n",
    "\n",
    "print(\"Created pipeline for answer similarity evaluation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38349765",
   "metadata": {},
   "source": [
    "Let's fit the vectorizer on all the text data we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d487041",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    font-family: monospace;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td.value pre {\n",
       "    color:rgb(255, 94, 0) !important;\n",
       "    background-color: transparent !important;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;tfidfvectorizer&#x27;, TfidfVectorizer(min_df=3)),\n",
       "                (&#x27;truncatedsvd&#x27;,\n",
       "                 TruncatedSVD(n_components=128, random_state=1))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>Pipeline</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.7/modules/generated/sklearn.pipeline.Pipeline.html\">?<span>Documentation for Pipeline</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('steps',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">steps&nbsp;</td>\n",
       "            <td class=\"value\">[(&#x27;tfidfvectorizer&#x27;, ...), (&#x27;truncatedsvd&#x27;, ...)]</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('transform_input',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">transform_input&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('memory',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">memory&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">verbose&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>TfidfVectorizer</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.7/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\">?<span>Documentation for TfidfVectorizer</span></a></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"tfidfvectorizer__\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('input',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">input&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;content&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('encoding',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">encoding&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;utf-8&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('decode_error',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">decode_error&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;strict&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('strip_accents',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">strip_accents&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('lowercase',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">lowercase&nbsp;</td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('preprocessor',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">preprocessor&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('tokenizer',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">tokenizer&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('analyzer',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">analyzer&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;word&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('stop_words',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">stop_words&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('token_pattern',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">token_pattern&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;(?u)\\\\b\\\\w\\\\w+\\\\b&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('ngram_range',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">ngram_range&nbsp;</td>\n",
       "            <td class=\"value\">(1, ...)</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_df',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_df&nbsp;</td>\n",
       "            <td class=\"value\">1.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_df',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_df&nbsp;</td>\n",
       "            <td class=\"value\">3</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_features',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_features&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('vocabulary',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">vocabulary&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('binary',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">binary&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('dtype',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">dtype&nbsp;</td>\n",
       "            <td class=\"value\">&lt;class &#x27;numpy.float64&#x27;&gt;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('norm',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">norm&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;l2&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('use_idf',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">use_idf&nbsp;</td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('smooth_idf',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">smooth_idf&nbsp;</td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('sublinear_tf',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">sublinear_tf&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>TruncatedSVD</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.7/modules/generated/sklearn.decomposition.TruncatedSVD.html\">?<span>Documentation for TruncatedSVD</span></a></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"truncatedsvd__\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_components',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_components&nbsp;</td>\n",
       "            <td class=\"value\">128</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('algorithm',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">algorithm&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;randomized&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_iter',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_iter&nbsp;</td>\n",
       "            <td class=\"value\">5</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_oversamples',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_oversamples&nbsp;</td>\n",
       "            <td class=\"value\">10</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('power_iteration_normalizer',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">power_iteration_normalizer&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;auto&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">random_state&nbsp;</td>\n",
       "            <td class=\"value\">1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('tol',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">tol&nbsp;</td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.fa-regular.fa-copy').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling.textContent.trim();\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "</script></body>"
      ],
      "text/plain": [
       "Pipeline(steps=[('tfidfvectorizer', TfidfVectorizer(min_df=3)),\n",
       "                ('truncatedsvd',\n",
       "                 TruncatedSVD(n_components=128, random_state=1))])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the pipeline on all available text data for comprehensive vocabulary\n",
    "# Combining LLM answers, original answers, and questions gives us the full text space\n",
    "all_texts = df_results.answer_llm + ' ' + df_results.answer_orig + ' ' + df_results.question\n",
    "print(f\"Fitting pipeline on {len(all_texts)} combined text samples...\")\n",
    "\n",
    "# Fit the vectorizer on the combined corpus\n",
    "pipeline_similarity.fit(all_texts)\n",
    "print(\"Pipeline fitted successfully!\")\n",
    "\n",
    "# Check the vocabulary size and embedding dimensions\n",
    "vectorizer = pipeline_similarity.named_steps['tfidfvectorizer']\n",
    "svd = pipeline_similarity.named_steps['truncatedsvd']\n",
    "print(f\"Vocabulary size: {len(vectorizer.vocabulary_)}\")\n",
    "print(f\"Embedding dimensions: {svd.n_components}\")\n",
    "\n",
    "all_texts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e700b388",
   "metadata": {},
   "source": [
    "Now use the `transform` method of the pipeline to create the embeddings and calculate the cosine similarity between each\n",
    "pair.\n",
    "\n",
    "What's the average cosine?\n",
    "\n",
    "This is how you do it:\n",
    "\n",
    "- For each answer pair, compute\n",
    "    - `v_llm` for the answer from the LLM \n",
    "    - `v_orig` for the original answer\n",
    "    - then compute the cosine between them\n",
    "- At the end, take the average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72cbdbb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average cosine similarity: 0.84\n"
     ]
    }
   ],
   "source": [
    "# Calculate cosine similarity between LLM-generated and original answers\n",
    "print(\"Calculating cosine similarities between answer pairs...\")\n",
    "\n",
    "similarities = []\n",
    "\n",
    "# Process each answer pair with progress tracking\n",
    "for i, row in tqdm(df_results.iterrows(), total=len(df_results), desc=\"Computing similarities\"):\n",
    "    # Transform both answers to embedding vectors using our fitted pipeline\n",
    "    v_llm = pipeline_similarity.transform([row[\"answer_llm\"]])[0]  # LLM-generated answer\n",
    "    v_orig = pipeline_similarity.transform([row[\"answer_orig\"]])[0]  # Original answer\n",
    "    \n",
    "    # Calculate cosine similarity between the two answer embeddings\n",
    "    similarity = cosine_simplified(v_llm, v_orig)\n",
    "    similarities.append(similarity)\n",
    "    \n",
    "    # Log progress every 100 samples\n",
    "    if (i + 1) % 100 == 0:\n",
    "        current_avg = np.mean(similarities)\n",
    "        print(f\"Processed {i + 1}/{len(df_results)} pairs, current avg similarity: {current_avg:.3f}\")\n",
    "\n",
    "# Calculate final statistics\n",
    "avg_cosine = np.mean(similarities)\n",
    "std_cosine = np.std(similarities)\n",
    "min_cosine = np.min(similarities)\n",
    "max_cosine = np.max(similarities)\n",
    "\n",
    "print(f\"\\nCosine Similarity Statistics:\")\n",
    "print(f\"Average cosine similarity: {avg_cosine:.3f}\")\n",
    "print(f\"Standard deviation: {std_cosine:.3f}\")\n",
    "print(f\"Minimum similarity: {min_cosine:.3f}\")\n",
    "print(f\"Maximum similarity: {max_cosine:.3f}\")\n",
    "\n",
    "avg_cosine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f29c433",
   "metadata": {},
   "source": [
    "## Q6. Rouge\n",
    "\n",
    "And alternative way to see how two texts are similar is ROUGE. \n",
    "\n",
    "This is a set of metrics that compares two answers based on the overlap of n-grams, word sequences, and word pairs.\n",
    "\n",
    "It can give a more nuanced view of text similarity than just cosine similarity alone.\n",
    "\n",
    "We don't need to implement it ourselves, there's a python package for it:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6136c6e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Install ROUGE package for text similarity evaluation\n",
    "# ROUGE (Recall-Oriented Understudy for Gisting Evaluation) is commonly used\n",
    "# for evaluating text summarization and generation tasks\n",
    "!pip install rouge -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8912faae",
   "metadata": {},
   "source": [
    "(The latest version at the moment of writing is `1.0.1`)\n",
    "\n",
    "Let's compute the ROUGE score between the answers at the index 10 of our dataframe (`doc_id=5170565b`)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f659a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge-1': {'r': 0.45454545454545453,\n",
       "  'p': 0.45454545454545453,\n",
       "  'f': 0.45454544954545456},\n",
       " 'rouge-2': {'r': 0.21621621621621623,\n",
       "  'p': 0.21621621621621623,\n",
       "  'f': 0.21621621121621637},\n",
       " 'rouge-l': {'r': 0.3939393939393939,\n",
       "  'p': 0.3939393939393939,\n",
       "  'f': 0.393939388939394}}"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import and initialize ROUGE scorer\n",
    "from rouge import Rouge\n",
    "rouge_scorer = Rouge()\n",
    "\n",
    "# Test ROUGE evaluation on a specific example (index 10)\n",
    "print(\"Testing ROUGE evaluation on sample answer pair (index 10):\")\n",
    "sample_row = df_results.iloc[10]\n",
    "\n",
    "print(f\"Document ID: {getattr(sample_row, 'doc_id', 'Not available')}\")\n",
    "print(f\"LLM Answer: {sample_row.answer_llm[:100]}...\")\n",
    "print(f\"Original Answer: {sample_row.answer_orig[:100]}...\")\n",
    "\n",
    "# Calculate ROUGE scores for this pair\n",
    "# get_scores returns a list with one dictionary containing all ROUGE metrics\n",
    "scores = rouge_scorer.get_scores(sample_row.answer_llm, sample_row.answer_orig)[0]\n",
    "\n",
    "print(\"\\nROUGE Scores for this pair:\")\n",
    "for rouge_type in ['rouge-1', 'rouge-2', 'rouge-l']:\n",
    "    print(f\"{rouge_type.upper()}:\")\n",
    "    print(f\"  Precision: {scores[rouge_type]['p']:.3f}\")\n",
    "    print(f\"  Recall: {scores[rouge_type]['r']:.3f}\")\n",
    "    print(f\"  F1-Score: {scores[rouge_type]['f']:.3f}\")\n",
    "\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df65768",
   "metadata": {},
   "source": [
    "There are three scores: `rouge-1`, `rouge-2` and `rouge-l`, and precision, recall and F1 score for each.\n",
    "\n",
    "* `rouge-1` - the overlap of unigrams,\n",
    "* `rouge-2` - bigrams,\n",
    "* `rouge-l` - the longest common subsequence\n",
    "\n",
    "For the 10th document, Rouge-1 F1 score is 0.45\n",
    "\n",
    "Let's compute it for the pairs in the entire dataframe.\n",
    "What's the average Rouge-1 F1?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1526c5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average ROUGE-1 F1 score: 0.35\n"
     ]
    }
   ],
   "source": [
    "# Calculate ROUGE-1 F1 scores for all answer pairs in the dataset\n",
    "print(\"Calculating ROUGE-1 F1 scores for all answer pairs...\")\n",
    "\n",
    "rouge_1_f1_scores = []\n",
    "rouge_2_f1_scores = []\n",
    "rouge_l_f1_scores = []\n",
    "\n",
    "# Process each answer pair with progress tracking\n",
    "for i, row in tqdm(df_results.iterrows(), total=len(df_results), desc=\"Computing ROUGE scores\"):\n",
    "    try:\n",
    "        # Calculate ROUGE scores for this answer pair\n",
    "        scores = rouge_scorer.get_scores(row[\"answer_llm\"], row[\"answer_orig\"])[0]\n",
    "        \n",
    "        # Extract F1 scores for different ROUGE variants\n",
    "        rouge_1_f1_scores.append(scores[\"rouge-1\"]['f'])  # Unigram overlap F1\n",
    "        rouge_2_f1_scores.append(scores[\"rouge-2\"]['f'])  # Bigram overlap F1\n",
    "        rouge_l_f1_scores.append(scores[\"rouge-l\"]['f'])  # Longest common subsequence F1\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing row {i}: {e}\")\n",
    "        # Add zeros for failed calculations to maintain alignment\n",
    "        rouge_1_f1_scores.append(0.0)\n",
    "        rouge_2_f1_scores.append(0.0)\n",
    "        rouge_l_f1_scores.append(0.0)\n",
    "\n",
    "# Calculate statistics for all ROUGE metrics\n",
    "def print_rouge_stats(scores, metric_name):\n",
    "    \"\"\"Print comprehensive statistics for a ROUGE metric.\"\"\"\n",
    "    avg_score = np.mean(scores)\n",
    "    std_score = np.std(scores)\n",
    "    min_score = np.min(scores)\n",
    "    max_score = np.max(scores)\n",
    "    \n",
    "    print(f\"\\n{metric_name} Statistics:\")\n",
    "    print(f\"  Average: {avg_score:.3f}\")\n",
    "    print(f\"  Std Dev: {std_score:.3f}\")\n",
    "    print(f\"  Min: {min_score:.3f}\")\n",
    "    print(f\"  Max: {max_score:.3f}\")\n",
    "    \n",
    "    return avg_score\n",
    "\n",
    "# Print statistics for all ROUGE variants\n",
    "rouge_1_avg = print_rouge_stats(rouge_1_f1_scores, \"ROUGE-1 F1\")\n",
    "rouge_2_avg = print_rouge_stats(rouge_2_f1_scores, \"ROUGE-2 F1\")\n",
    "rouge_l_avg = print_rouge_stats(rouge_l_f1_scores, \"ROUGE-L F1\")\n",
    "\n",
    "print(f\"\\n=== FINAL RESULTS ===\")\n",
    "print(f\"Average ROUGE-1 F1 score: {rouge_1_avg:.3f}\")\n",
    "print(f\"Average ROUGE-2 F1 score: {rouge_2_avg:.3f}\")\n",
    "print(f\"Average ROUGE-L F1 score: {rouge_l_avg:.3f}\")\n",
    "\n",
    "rouge_1_avg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3351644",
   "metadata": {},
   "source": [
    "## Summary and Key Takeaways\n",
    "\n",
    "This notebook demonstrated comprehensive evaluation techniques for search systems and RAG pipelines:\n",
    "\n",
    "### Search System Evaluation\n",
    "1. **MinSearch with Boosting**: Evaluated text-based search with custom field weights\n",
    "2. **Vector Search (TF-IDF + SVD)**: Compared single-field vs combined-field embeddings\n",
    "3. **Modern Vector Search (Qdrant + Jina)**: Tested state-of-the-art embedding models\n",
    "\n",
    "### Answer Quality Evaluation\n",
    "1. **Cosine Similarity**: Measured semantic similarity between generated and reference answers\n",
    "2. **ROUGE Metrics**: Evaluated text overlap using industry-standard metrics\n",
    "\n",
    "### Performance Insights\n",
    "- **Hit Rate**: Measures if any relevant document appears in top-k results\n",
    "- **MRR (Mean Reciprocal Rank)**: Considers the position of the first relevant document\n",
    "- **Combined text fields** often outperform single fields for vector search\n",
    "- **Modern embedding models** (like Jina) typically provide better semantic understanding\n",
    "- **Multiple evaluation metrics** provide different perspectives on system performance\n",
    "\n",
    "### Best Practices Learned\n",
    "1. Always use multiple evaluation metrics for comprehensive assessment\n",
    "2. Compare different approaches systematically using the same ground truth\n",
    "3. Consider both retrieval quality (Hit Rate, MRR) and answer quality (Cosine, ROUGE)\n",
    "4. Use progress tracking and detailed logging for long-running evaluations\n",
    "5. Implement proper error handling for robust evaluation pipelines"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmenvs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
