{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "606ab767-6199-4910-a503-b132f4f2c046",
   "metadata": {},
   "source": [
    "## Week 2 - Homework: Vector Search\n",
    "\n",
    "In this homework, we will learn more about vector search\n",
    "and embedding. Like in the module, we will use Qdrant and\n",
    "fastembed\n",
    "\n",
    "> It's possible that your answers won't match exactly. If it's the case, select the closest one.\n",
    "\n",
    "## Embeddings\n",
    "\n",
    "Qdrant uses [fastembed](https://github.com/qdrant/fastembed)\n",
    "under the hood to turn text into vectors. \n",
    "\n",
    "We will now explore this library\n",
    "\n",
    "Make sure it's installed:\n",
    "\n",
    "```bash\n",
    "pip install fastembed\n",
    "```\n",
    "\n",
    "Import it: \n",
    "\n",
    "```python\n",
    "from fastembed import TextEmbedding\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362f9dc5-1502-4bd8-8bd4-eae4488f9809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install or upgrade necessary libraries:\n",
    "# - fastembed: library for generating text embeddings\n",
    "# - qdrant-client with fastembed extension: client for Qdrant vector database \n",
    "# - sentence-transformers: library for computing dense vector representations\n",
    "# The -q flag makes the installation output less verbose\n",
    "!pip install --upgrade fastembed \"qdrant-client[fastembed]>=1.14.2\" sentence-transformers -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd434ea4-f333-4a26-880d-160dc8c432bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient, models\n",
    "from fastembed import TextEmbedding\n",
    "import numpy as np\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18bddba1-6d15-4c4a-a78b-df7ca6846802",
   "metadata": {},
   "source": [
    "## Q1. Embedding the query\n",
    "\n",
    "Embed the query: `'I just discovered the course. Can I join now?'`.\n",
    "Use the `'jinaai/jina-embeddings-v2-small-en'` model. \n",
    "\n",
    "You should get a numpy array of size 512.\n",
    "\n",
    "What's the minimal value in this array?\n",
    "\n",
    "* -0.51\n",
    "* -0.11\n",
    "* 0\n",
    "* 0.51\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9c33f02b-de4e-4925-b6d9-6951d7c85b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#docker pull qdrant/qdrant\n",
    "#docker run -p 6333:6333 -p 6334:6334 -v \"$(pwd)/qdrant_storage:/qdrant/storage:z\" qdrant/qdrant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72af9249-8ced-47d9-895e-aa057eff5c37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a84b594977d24b85b15b9a9fc81f4e15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f796fcd40cdf4694946f828f661aa009",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6262e15681ae4f0480126db08297769e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dcc5dff8c874c0e85190ac2b9c416e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7309b71515c2427c8934593c7d7a0bff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/367 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9309115a95ef4bad9ce71750ab367e24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "onnx/model.onnx:   0%|          | 0.00/130M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = 'I just discovered the course. Can I join now?'\n",
    "model_name = 'jinaai/jina-embeddings-v2-small-en'\n",
    "\n",
    "model = TextEmbedding(model_name=model_name)\n",
    "embeddings_query = list(model.embed([query]))\n",
    "len(embeddings_query[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe2b2ab-af4c-42f2-9cd4-b728b6aaa828",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(-0.117)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the minimum value in the embedding vector and round it to 3 decimal places\n",
    "# This answers Q1 which asks for the minimal value in the embedding array\n",
    "round(np.min(embeddings_query[0]), 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f3476f-8dfb-4bc4-b12b-391c38234bea",
   "metadata": {},
   "source": [
    "## Cosine similarity\n",
    "\n",
    "The vectors that our embedding model returns are already normalized: their length is 1.0.\n",
    "\n",
    "You can check that by using the `norm` function:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "np.linalg.norm(q)\n",
    "```\n",
    "\n",
    "Which means that we can simply compute the dot product between\n",
    "two vectors to learn the cosine similarity between them.\n",
    "\n",
    "For example, if you compute the cosine of the query vector with itself, the result will be 1.0:\n",
    "\n",
    "```python\n",
    "q.dot(q)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "334de6e2-74b7-4e67-a86a-8303a354e1d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(1.0), np.float64(1.0000000000000002))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the norm (length) of the embedding vector\n",
    "norm = np.linalg.norm(embeddings_query[0])\n",
    "\n",
    "# Calculate dot product of the vector with itself\n",
    "dot_product = embeddings_query[0].dot(embeddings_query[0])\n",
    "\n",
    "# Display both values to verify that the vector is normalized\n",
    "# If normalized: norm ≈ 1.0 and dot_product ≈ 1.0 \n",
    "norm, dot_product"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3d6e87-b412-43c4-8074-23fa87d175fe",
   "metadata": {},
   "source": [
    "## Q2. Cosine similarity with another vector\n",
    "\n",
    "Now let's embed this document:\n",
    "\n",
    "```python\n",
    "doc = 'Can I still join the course after the start date?'\n",
    "```\n",
    "\n",
    "What's the cosine similarity between the vector for the query\n",
    "and the vector for the document?\n",
    "\n",
    "* 0.3\n",
    "* 0.5\n",
    "* 0.7\n",
    "* 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de57b27a-8e88-4b45-9bc4-dd07af12d1a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.9008528895674548)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a document text that we want to compare with our query\n",
    "doc = 'Can I still join the course after the start date?'\n",
    "\n",
    "# Convert the document text into an embedding vector using the same model\n",
    "embeddings_doc = list(model.embed([doc]))\n",
    "\n",
    "# Calculate cosine similarity between query and document vectors\n",
    "# Since both vectors are normalized, dot product equals cosine similarity\n",
    "embeddings_doc[0].dot(embeddings_query[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96181386-e294-4893-b1ac-7a98c6bc10e9",
   "metadata": {},
   "source": [
    "## Q3. Ranking by cosine\n",
    "\n",
    "For Q3 and Q4 we will use these documents:\n",
    "\n",
    "```python\n",
    "documents = [{'text': \"Yes, even if you don't register, you're still eligible to submit the homeworks.\\nBe aware, however, that there will be deadlines for turning in the final projects. So don't leave everything for the last minute.\",\n",
    "  'section': 'General course-related questions',\n",
    "  'question': 'Course - Can I still join the course after the start date?',\n",
    "  'course': 'data-engineering-zoomcamp'},\n",
    " {'text': 'Yes, we will keep all the materials after the course finishes, so you can follow the course at your own pace after it finishes.\\nYou can also continue looking at the homeworks and continue preparing for the next cohort. I guess you can also start working on your final capstone project.',\n",
    "  'section': 'General course-related questions',\n",
    "  'question': 'Course - Can I follow the course after it finishes?',\n",
    "  'course': 'data-engineering-zoomcamp'},\n",
    " {'text': \"The purpose of this document is to capture frequently asked technical questions\\nThe exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\\nSubscribe to course public Google Calendar (it works from Desktop only).\\nRegister before the course starts using this link.\\nJoin the course Telegram channel with announcements.\\nDon’t forget to register in DataTalks.Club's Slack and join the channel.\",\n",
    "  'section': 'General course-related questions',\n",
    "  'question': 'Course - When will the course start?',\n",
    "  'course': 'data-engineering-zoomcamp'},\n",
    " {'text': 'You can start by installing and setting up all the dependencies and requirements:\\nGoogle cloud account\\nGoogle Cloud SDK\\nPython 3 (installed with Anaconda)\\nTerraform\\nGit\\nLook over the prerequisites and syllabus to see if you are comfortable with these subjects.',\n",
    "  'section': 'General course-related questions',\n",
    "  'question': 'Course - What can I do before the course starts?',\n",
    "  'course': 'data-engineering-zoomcamp'},\n",
    " {'text': 'Star the repo! Share it with friends if you find it useful ❣️\\nCreate a PR if you see you can improve the text or the structure of the repository.',\n",
    "  'section': 'General course-related questions',\n",
    "  'question': 'How can we contribute to the course?',\n",
    "  'course': 'data-engineering-zoomcamp'}]\n",
    "```\n",
    "\n",
    "Compute the embeddings for the text field, and compute the \n",
    "cosine between the query vector and all the documents.\n",
    "\n",
    "What's the document index with the highest similarity? (Indexing starts from 0):\n",
    "\n",
    "- 0\n",
    "- 1\n",
    "- 2\n",
    "- 3\n",
    "- 4\n",
    "\n",
    "Hint: if you put all the embeddings of the text field in one matrix `V` (a single 2-dimensional numpy array), then\n",
    "computing the cosine becomes a matrix multiplication:\n",
    "\n",
    "```python\n",
    "V.dot(q)\n",
    "```\n",
    "\n",
    "If this hint is rather confusing you than helping, feel free\n",
    "to ignore it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "129c29e4-abcb-4b49-9b58-0e2178b8691d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents = [{'text': \"Yes, even if you don't register, you're still eligible to submit the homeworks.\\nBe aware, however, that there will be deadlines for turning in the final projects. So don't leave everything for the last minute.\",\n",
    "              'section': 'General course-related questions',\n",
    "              'question': 'Course - Can I still join the course after the start date?',\n",
    "              'course': 'data-engineering-zoomcamp'},\n",
    "             {'text': 'Yes, we will keep all the materials after the course finishes, so you can follow the course at your own pace after it finishes.\\nYou can also continue looking at the homeworks and continue preparing for the next cohort. I guess you can also start working on your final capstone project.',\n",
    "              'section': 'General course-related questions',\n",
    "              'question': 'Course - Can I follow the course after it finishes?',\n",
    "              'course': 'data-engineering-zoomcamp'},\n",
    "             {'text': \"The purpose of this document is to capture frequently asked technical questions\\nThe exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\\nSubscribe to course public Google Calendar (it works from Desktop only).\\nRegister before the course starts using this link.\\nJoin the course Telegram channel with announcements.\\nDon’t forget to register in DataTalks.Club's Slack and join the channel.\",\n",
    "              'section': 'General course-related questions',\n",
    "              'question': 'Course - When will the course start?',\n",
    "              'course': 'data-engineering-zoomcamp'},\n",
    "             {'text': 'You can start by installing and setting up all the dependencies and requirements:\\nGoogle cloud account\\nGoogle Cloud SDK\\nPython 3 (installed with Anaconda)\\nTerraform\\nGit\\nLook over the prerequisites and syllabus to see if you are comfortable with these subjects.',\n",
    "              'section': 'General course-related questions',\n",
    "              'question': 'Course - What can I do before the course starts?',\n",
    "              'course': 'data-engineering-zoomcamp'},\n",
    "             {'text': 'Star the repo! Share it with friends if you find it useful ❣️\\nCreate a PR if you see you can improve the text or the structure of the repository.',\n",
    "              'section': 'General course-related questions',\n",
    "              'question': 'How can we contribute to the course?',\n",
    "              'course': 'data-engineering-zoomcamp'}\n",
    "            ]\n",
    "\n",
    "embeddings_vector = []\n",
    "\n",
    "for document in documents:\n",
    "    embeddings_doc = list(model.embed([document['text']]))\n",
    "    embeddings_vector.append(embeddings_doc[0])\n",
    "\n",
    "cos_sim = np.array(embeddings_vector).dot(embeddings_query[0])\n",
    "np.argmin(cos_sim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec047bf-962e-4e98-9107-7e09c8fdffd6",
   "metadata": {},
   "source": [
    "## Q4. Ranking by cosine, version two\n",
    "\n",
    "Now let's calculate a new field, which is a concatenation of\n",
    "`question` and `text`:\n",
    "\n",
    "```python\n",
    "full_text = doc['question'] + ' ' + doc['text']\n",
    "``` \n",
    "\n",
    "Embed this field and compute the cosine between it and the\n",
    "query vector. What's the highest scoring document?\n",
    "\n",
    "- 0\n",
    "- 1\n",
    "- 2\n",
    "- 3\n",
    "- 4\n",
    "\n",
    "Is it different from Q3? If yes, why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57b1148c-c147-468d-aae8-43a95d848902",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_vector = []\n",
    "\n",
    "for document in documents:\n",
    "    full_text = document['question'] + ' ' + document['text']\n",
    "    embeddings_doc = list(model.embed([full_text]))\n",
    "    embeddings_vector.append(embeddings_doc[0])\n",
    "\n",
    "cos_sim = np.array(embeddings_vector).dot(embeddings_query[0])\n",
    "np.argmax(cos_sim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89613d58-ce61-47e2-aa0d-4487ec423223",
   "metadata": {},
   "source": [
    "Yes, in general it can be different because:\n",
    "+ In Q3 you are comparing only the body of the text.\n",
    "+ In Q4, the `question` provides key information that improves the semantic similarity if the query is similar to the original question."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2863ce57-63de-4eb1-b523-1229a00fdc75",
   "metadata": {},
   "source": [
    "## Q5. Selecting the embedding model\n",
    "\n",
    "Now let's select a smaller embedding model.\n",
    "What's the smallest dimensionality for models in `fastembed`?\n",
    "\n",
    "- 128\n",
    "- 256\n",
    "- 384\n",
    "- 512\n",
    "\n",
    "One of these models is `BAAI/bge-small-en`. Let's use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9366b34-2c2f-481a-afad-85127a191856",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': 'BAAI/bge-small-en',\n",
       " 'sources': {'hf': 'Qdrant/bge-small-en',\n",
       "  'url': 'https://storage.googleapis.com/qdrant-fastembed/BAAI-bge-small-en.tar.gz',\n",
       "  '_deprecated_tar_struct': True},\n",
       " 'model_file': 'model_optimized.onnx',\n",
       " 'description': 'Text embeddings, Unimodal (text), English, 512 input tokens truncation, Prefixes for queries/documents: necessary, 2023 year.',\n",
       " 'license': 'mit',\n",
       " 'size_in_GB': 0.13,\n",
       " 'additional_files': [],\n",
       " 'dim': 384,\n",
       " 'tasks': {}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_list = TextEmbedding.list_supported_models()\n",
    "\n",
    "dimensions = []\n",
    "for model in models_list:\n",
    "    dimensions.append(model['dim'])\n",
    "    \n",
    "models_list[np.array(dimensions).argmin()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39937e38-921a-41bf-8ecf-63f0d31f3209",
   "metadata": {},
   "source": [
    "## Q6. Indexing with qdrant (2 points)\n",
    "\n",
    "For the last question, we will use more documents.\n",
    "\n",
    "We will select only FAQ records from our ml zoomcamp:\n",
    "\n",
    "```python\n",
    "import requests \n",
    "\n",
    "docs_url = 'https://github.com/alexeygrigorev/llm-rag-workshop/raw/main/notebooks/documents.json'\n",
    "docs_response = requests.get(docs_url)\n",
    "documents_raw = docs_response.json()\n",
    "\n",
    "\n",
    "documents = []\n",
    "\n",
    "for course in documents_raw:\n",
    "    course_name = course['course']\n",
    "    if course_name != 'machine-learning-zoomcamp':\n",
    "        continue\n",
    "\n",
    "    for doc in course['documents']:\n",
    "        doc['course'] = course_name\n",
    "        documents.append(doc)\n",
    "```\n",
    "\n",
    "Add them to qdrant using the model form Q5.\n",
    "\n",
    "When adding the data, use both question and answer fields:\n",
    "\n",
    "```python\n",
    "text = doc['question'] + ' ' + doc['text']\n",
    "```\n",
    "\n",
    "After the data is inserted, use the question from Q1 for querying the collection.\n",
    "\n",
    "What's the highest score in the results?\n",
    "(The score for the first returned record):\n",
    "\n",
    "- 0.97\n",
    "- 0.87\n",
    "- 0.77\n",
    "- 0.67"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7606706-f957-4345-9f5d-8c4987567178",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_url = 'https://github.com/alexeygrigorev/llm-rag-workshop/raw/main/notebooks/documents.json'\n",
    "docs_response = requests.get(docs_url)\n",
    "documents_raw = docs_response.json()\n",
    "\n",
    "\n",
    "documents = []\n",
    "\n",
    "for course in documents_raw:\n",
    "    course_name = course['course']\n",
    "    if course_name != 'machine-learning-zoomcamp':\n",
    "        continue\n",
    "\n",
    "    for doc in course['documents']:\n",
    "        doc['course'] = course_name\n",
    "        documents.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "51d5f617-ea94-436d-bd01-7a70dd4e8b1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'Machine Learning Zoomcamp FAQ\\nThe purpose of this document is to capture frequently asked technical questions.\\nWe did this for our data engineering course and it worked quite well. Check this document for inspiration on how to structure your questions and answers:\\nData Engineering Zoomcamp FAQ\\nIn the course GitHub repository there’s a link. Here it is: https://airtable.com/shryxwLd0COOEaqXo\\nwork',\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'How do I sign up?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'text': 'The course videos are pre-recorded, you can start watching the course right now.\\nWe will also occasionally have office hours - live sessions where we will answer your questions. The office hours sessions are recorded too.\\nYou can see the office hours as well as the pre-recorded course videos in the course playlist on YouTube.',\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Is it going to be live? When?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'text': 'Everything is recorded, so you won’t miss anything. You will be able to ask your questions for office hours in advance and we will cover them during the live stream. Also, you can always ask questions in Slack.',\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'What if I miss a session?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'text': \"The bare minimum. The focus is more on practice, and we'll cover the theory only on the intuitive level.: https://mlbookcamp.com/article/python\\nFor example, we won't derive the gradient update rule for logistic regression (there are other great courses for that), but we'll cover how to use logistic regression and make sense of the results.\",\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'How much theory will you cover?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'text': \"Yes! We'll cover some linear algebra in the course, but in general, there will be very few formulas, mostly code.\\nHere are some interesting videos covering linear algebra that you can already watch: ML Zoomcamp 1.8 - Linear Algebra Refresher from Alexey Grigorev or the excellent playlist from 3Blue1Brown Vectors | Chapter 1, Essence of linear algebra. Never hesitate to ask the community for help if you have any question.\\n(Mélanie Fouesnard)\",\n",
       "  'section': 'General course-related questions',\n",
       "  'question': \"I don't know math. Can I take the course?\",\n",
       "  'course': 'machine-learning-zoomcamp'}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e7e1fd5-67a9-4ab0-a554-a2194ce01a88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f408e63f963343efa5efe2be066a5b81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14219655d12c439c9ee44b6493d742b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5deb1f24f9974b6a88d11fd2a2293ecf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/366 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33a441576cf84932b62e45bddf929e74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "600576c42556455f81f44ff474545bc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model_optimized.onnx:   0%|          | 0.00/133M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e62bd7e54512457cb0f1bfaf4c5b49eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/701 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bad pipe message: %s [b'\"Google Chrome\";v=\"137\", \"Chromium\";v=\"137\", \"Not/A)Brand']\n",
      "Bad pipe message: %s [b'v=\"24\"\\r\\nsec-ch-ua-mobile: ?0\\r\\nsec', b'h-ua-platform: \"Windows\"\\r\\nUpgrade-Insecure-R', b'uests: 1\\r\\nUser-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Geck', b' Chrome/137.0.0.0 Safari/537.36\\r\\nAccept: text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,imag', b'webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7\\r\\nSec-Fetch-Site: none\\r\\nSec-Fetch-Mo', b': navigate\\r\\nSec-Fetch-User: ?1\\r\\nSec-Fetch-Dest: document\\r\\nAccept-Encoding: gzip, deflate, br, zstd\\r', b'ccept-Lan', b'age: ar-EG,ar;q=0.9,en-US;q=0.8,en;q=0.7\\r\\nCookie: adminer_permanent=; grafana_session=3540cfce971f6d61', b'736b2735647ccd; grafana_session_expiry=1750999677\\r\\n\\r']\n",
      "Bad pipe message: %s [b'ol: max-age=0\\r\\nsec-ch-ua: \"Google Chrome\";v=\"137\", \"Chromium\";v=\"137\", \"Not/A)Brand\";v=\"24\"\\r\\nsec-ch-ua-mobile: ?0\\r\\n']\n",
      "Bad pipe message: %s [b'c-ch-ua-platform: \"Windows\"\\r\\nUpgrade-Insecure-Requests: 1\\r\\nUser-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) A', b'leWebKit/537.36 (KHTML, like Gecko) Chrome/137.0.0.0 Safari/537.36\\r\\nAccept: text/html,application/xhtml+xml,app']\n",
      "Bad pipe message: %s [b'cation/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7\\r\\nSec-Fet', b'-Site: none\\r\\nSec-Fetch-Mode: navigate\\r\\nSec-Fetch-User: ?1\\r\\nSec-Fetch-Dest: document\\r\\nAccept-Encodi']\n",
      "Bad pipe message: %s [b'ol: max-age=0\\r\\nsec-ch-ua: \"Google Chrome\";v=\"137\", \"Chromium\";v=\"137\", \"Not/A)Brand\";v=\"24\"\\r\\nsec-ch-ua-mobile: ?0\\r\\n']\n",
      "Bad pipe message: %s [b'c-ch-ua-platform: \"Windows\"\\r\\nUpgrade-Insecure-Requests: 1\\r\\nUser-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) A', b'leWebKit/537.36 (KHTML, like Gecko) Chrome/137.0.0.0 Safari/537.36\\r\\nAccept: text/html,application/xhtml+xml,app']\n",
      "Bad pipe message: %s [b'cation/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7\\r\\nSec-Fet', b'-Site: none\\r\\nSec-Fetch-Mode: navigate\\r\\nSec-Fetch-User: ?1\\r\\nSec-Fetch-Dest: document\\r\\nAccept-Encodi']\n",
      "Bad pipe message: %s [b'ol: max-age=0\\r\\nsec-ch-ua: \"Google Chrome\";v=\"137\", \"Chromium\";v=\"137\", \"Not/A)Brand\";v=\"24\"\\r\\nsec-ch-ua-mobile: ?0\\r\\n']\n",
      "Bad pipe message: %s [b'c-ch-ua-platform: \"Windows\"\\r\\nUpgrade-Insecure-Requests: 1\\r\\nUser-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) A', b'leWebKit/537.36 (KHTML, like Gecko) Chrome/137.0.0.0 Safari/537.36\\r\\nAccept: text/html,application/xhtml+xml,app']\n",
      "Bad pipe message: %s [b'cation/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7\\r\\nSec-Fet', b'-Site: none\\r\\nSec-Fetch-Mode: navigate\\r\\nSec-Fetch-User: ?1\\r\\nSec-Fetch-Dest: document\\r\\nAccept-Encodi']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "UpdateResult(operation_id=0, status=<UpdateStatus.COMPLETED: 'completed'>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = QdrantClient(\":memory:\")  # Use in-memory storage instead of connecting to a server\n",
    "\n",
    "EMBEDDING_DIMENSIONALITY = 384\n",
    "collection_name = \"ml-zoomcamp-rag\"\n",
    "client.create_collection(\n",
    "    collection_name=collection_name,\n",
    "    vectors_config=models.VectorParams(\n",
    "        size=EMBEDDING_DIMENSIONALITY,\n",
    "        distance=models.Distance.COSINE\n",
    "    )\n",
    ")\n",
    "\n",
    "model_name = 'BAAI/bge-small-en'\n",
    "points = []\n",
    "id_ = 0\n",
    "for doc in documents:\n",
    "    text = doc['question'] + ' ' + doc['text']\n",
    "    point = models.PointStruct(\n",
    "        id=id_,\n",
    "        vector=models.Document(text=text, model=model_name),\n",
    "        payload={\n",
    "            \"text\": text,\n",
    "            \"section\": doc['section'],\n",
    "            \"course\": doc['course']\n",
    "        }\n",
    "    )\n",
    "    points.append(point)\n",
    "\n",
    "    id_ += 1\n",
    "\n",
    "client.upsert(\n",
    "    collection_name=collection_name,\n",
    "    points=points\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cfcdce02-86f9-4284-a528-ed5ee2dae637",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query, limit=5, score_threshold=0.0):\n",
    "    \"\"\"\n",
    "    Search for documents in Qdrant vector database using semantic similarity.\n",
    "    \n",
    "    Args:\n",
    "        query (str): The search query text\n",
    "        limit (int): Maximum number of results to return\n",
    "        score_threshold (float): Minimum relevance score (0.0-1.0) for results\n",
    "        \n",
    "    Returns:\n",
    "        SearchResult object containing matching points\n",
    "    \"\"\"\n",
    "    results = client.query_points(\n",
    "        collection_name=collection_name,\n",
    "        query=models.Document(\n",
    "            text=query,\n",
    "            model=model_name  # Using BAAI/bge-small-en model\n",
    "        ),\n",
    "        limit=limit,\n",
    "        score_threshold=score_threshold,\n",
    "        with_payload=True\n",
    "    )\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Get the search results and extract the top match\n",
    "result = search(query, limit=1).points[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4394e580-b028-4140-a02c-d391baaa32a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I just discovered the course. Can I join now?'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ce1ffd16-5932-48d8-a184-777c67b52a4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The course has already started. Can I still join it? Yes, you can. You won’t be able to submit some of the homeworks, but you can still take part in the course.\\nIn order to get a certificate, you need to submit 2 out of 3 course projects and review 3 peers’ Projects by the deadline. It means that if you join the course at the end of November and manage to work on two projects, you will still be eligible for a certificate.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.payload[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cbaa6dad-55ef-4624-bcef-7968a13f2845",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8703173141122041"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
